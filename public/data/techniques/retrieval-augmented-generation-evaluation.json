{
  "slug": "retrieval-augmented-generation-evaluation",
  "name": "Retrieval-Augmented Generation Evaluation",
  "description": "RAG evaluation assesses systems combining retrieval and generation by measuring retrieval quality, generation faithfulness, and overall performance. This technique evaluates whether retrieved context is relevant, whether responses faithfully represent information without hallucination, and how systems handle insufficient context. Key metrics include retrieval precision/recall, answer relevance, faithfulness scores, and citation accuracy.",
  "assurance_goals": [
    "Reliability",
    "Transparency",
    "Explainability"
  ],
  "tags": [
    "applicable-models/architecture/neural-networks/transformer/llm",
    "applicable-models/paradigm/generative",
    "applicable-models/requirements/black-box",
    "assurance-goal-category/reliability",
    "assurance-goal-category/transparency",
    "assurance-goal-category/explainability",
    "assurance-goal-category/explainability/explains/internal-mechanisms",
    "assurance-goal-category/explainability/property/fidelity",
    "data-requirements/labeled-data-required",
    "data-type/text",
    "evidence-type/quantitative-metric",
    "evidence-type/qualitative-assessment",
    "evidence-type/test-results",
    "expertise-needed/ml-engineering",
    "expertise-needed/domain-expertise",
    "lifecycle-stage/model-evaluation",
    "lifecycle-stage/post-deployment",
    "technique-type/testing",
    "technique-type/analytical"
  ],
  "example_use_cases": [
    {
      "description": "Evaluating a technical support knowledge system at a software company to ensure it retrieves relevant troubleshooting documentation and generates accurate solutions without fabricating configuration steps or commands not present in official documentation.",
      "goal": "Reliability"
    },
    {
      "description": "Assessing whether a legal research assistant properly cites source documents when generating case summaries, enabling lawyers to verify information and trace conclusions back to authoritative sources.",
      "goal": "Transparency"
    },
    {
      "description": "Evaluating a scientific literature review system to verify generated research summaries accurately synthesize findings across papers, clearly indicating contradictory results or missing evidence in the knowledge base.",
      "goal": "Explainability"
    },
    {
      "description": "Evaluating a clinical decision support system that retrieves relevant medical literature and patient records to ensure generated treatment recommendations accurately reflect evidence-based guidelines without extrapolating beyond available clinical data.",
      "goal": "Reliability"
    },
    {
      "description": "Assessing a government benefits information chatbot to verify it retrieves relevant policy documents and accurately communicates eligibility criteria without hallucinating benefits, amounts, or requirements that could mislead citizens seeking assistance.",
      "goal": "Transparency"
    }
  ],
  "limitations": [
    {
      "description": "Evaluation requires high-quality ground truth datasets with known correct retrievals and answers, which may be expensive or impossible to create for specialized domains."
    },
    {
      "description": "Faithfulness assessment can be subjective and difficult to automate, often requiring human judgment to determine whether responses accurately represent retrieved context."
    },
    {
      "description": "Trade-offs between retrieval precision and recall mean optimizing for one metric may degrade the other, requiring domain-specific balancing decisions."
    },
    {
      "description": "Metrics may not capture subtle quality issues like incomplete answers, misleading emphasis, or failure to synthesize information from multiple retrieved sources."
    },
    {
      "description": "Evaluating multi-hop reasoning—where answers require synthesising information across multiple retrieved documents—is particularly challenging, as standard metrics may not capture whether the system correctly chains information or makes unsupported logical leaps."
    },
    {
      "description": "Difficult to isolate whether poor performance stems from retrieval failures (finding wrong documents), generation failures (misusing correct documents), or interaction effects, complicating diagnosis and improvement efforts."
    }
  ],
  "resources": [
    {
      "title": "Evaluation of Retrieval-Augmented Generation: A Survey",
      "url": "https://www.semanticscholar.org/paper/3c6a6c8de005ef5722a54847747f65922e79d622",
      "source_type": "technical_paper",
      "authors": [
        "Hao Yu",
        "Aoran Gan",
        "Kai Zhang",
        "Shiwei Tong",
        "Qi Liu",
        "Zhaofeng Liu"
      ]
    },
    {
      "title": "LLM RAG Evaluation with MLflow Example Notebook | MLflow",
      "url": "https://mlflow.org/docs/3.0.1/llms/rag/notebooks/mlflow-e2e-evaluation/",
      "source_type": "tutorial"
    },
    {
      "title": "hoorangyee/LRAGE",
      "url": "https://github.com/hoorangyee/LRAGE",
      "source_type": "software_package"
    },
    {
      "title": "Evaluating RAG Applications with RAGAs | Towards Data Science",
      "url": "https://towardsdatascience.com/evaluating-rag-applications-with-ragas-81d67b0ee31a/",
      "source_type": "tutorial"
    },
    {
      "title": "Enhancing the Precision and Interpretability of Retrieval-Augmented Generation (RAG) in Legal Technology: A Survey",
      "url": "https://www.semanticscholar.org/paper/f51e92ce3f63cf04c26374c0ca33a2a751931cf6",
      "source_type": "technical_paper",
      "authors": [
        "Mahd Hindi",
        "Linda Mohammed",
        "Ommama Maaz",
        "Abdulmalik Alwarafy"
      ]
    }
  ],
  "related_techniques": [
    "hallucination-detection",
    "chain-of-thought-faithfulness-evaluation",
    "out-of-domain-detection",
    "prompt-robustness-testing"
  ]
}