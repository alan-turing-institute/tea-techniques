{
  "slug": "ridge-regression-surrogates",
  "name": "Ridge Regression Surrogates",
  "description": "This technique approximates a complex model by training a ridge regression (a linear model with L2 regularisation) on the original model's predictions. The ridge regression serves as a global surrogate that balances fidelity and interpretability, capturing the main linear relationships that the complex model learned whilst ignoring noise due to regularisation. This approach is particularly useful when stakeholders need to understand the overall behaviour of a complex model through transparent linear coefficients.",
  "assurance_goals": [
    "Explainability",
    "Transparency"
  ],
  "tags": [
    "assurance-goal-category/explainability",
    "assurance-goal-category/explainability/surrogate-models/global-surrogates",
    "assurance-goal-category/explainability/explains/feature-importance",
    "assurance-goal-category/explainability/explains/decision-boundaries",
    "assurance-goal-category/explainability/property/fidelity",
    "assurance-goal-category/explainability/property/comprehensibility",
    "assurance-goal-category/transparency",
    "data-requirements/no-special-requirements",
    "data-type/any",
    "evidence-type/structured-output",
    "expertise-needed/ml-engineering",
    "explanatory-scope/global",
    "lifecycle-stage/model-development",
    "technique-type/algorithmic",
    "applicable-models/architecture/model-agnostic",
    "applicable-models/requirements/black-box"
  ],
  "example_use_cases": [
    {
      "description": "Approximating a complex ensemble model used for credit scoring with a ridge regression surrogate to identify the most influential features (income, credit history, debt-to-income ratio) and their linear relationships for regulatory compliance reporting.",
      "goal": "Explainability"
    },
    {
      "description": "Creating a ridge regression surrogate of a neural network used for medical diagnosis to understand which patient symptoms and biomarkers have the strongest linear predictive relationships with disease outcomes.",
      "goal": "Explainability"
    },
    {
      "description": "Creating an interpretable approximation of a complex insurance pricing model for regulatory compliance, enabling stakeholders to understand and validate the decision-making process through transparent linear relationships.",
      "goal": "Transparency"
    }
  ],
  "limitations": [
    {
      "description": "Linear approximation may miss important non-linear relationships and interactions captured by the original complex model."
    },
    {
      "description": "Requires a representative dataset to train the surrogate model, which may not be available or may be expensive to generate."
    },
    {
      "description": "Ridge regularisation may oversimplify the model by shrinking coefficients, potentially hiding important but less dominant features."
    },
    {
      "description": "Surrogate fidelity depends on how well linear relationships approximate the original model's behaviour across the entire input space."
    }
  ],
  "resources": [
    {
      "title": "scikit-learn Ridge Regression Documentation",
      "url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html",
      "source_type": "documentation"
    },
    {
      "title": "Interpretable Machine Learning: A Guide for Making Black Box Models Explainable",
      "url": "https://christophm.github.io/interpretable-ml-book/global.html",
      "source_type": "documentation"
    },
    {
      "title": "Interpreting Blackbox Models via Model Extraction",
      "url": "https://arxiv.org/abs/1705.08504",
      "source_type": "technical_paper",
      "authors": [
        "Osbert Bastani",
        "Carolyn Kim",
        "Hamsa Bastani"
      ],
      "publication_date": "2017-05-23"
    },
    {
      "title": "Model extraction and defenses on generative adversarial networks",
      "url": "https://ieeexplore.ieee.org/document/8424633",
      "source_type": "technical_paper",
      "authors": [
        "Yuheng Jia",
        "Zhuofu Tian",
        "Mulin Xiong",
        "Jiaxin Ding"
      ],
      "publication_date": "2018-06-20"
    }
  ],
  "complexity_rating": 3,
  "computational_cost_rating": 2,
  "related_techniques": [
    "local-interpretable-model-agnostic-explanations",
    "rulefit",
    "partial-dependence-plots",
    "coefficient-magnitudes-in-linear-models"
  ]
}