{
  "slug": "synthetic-data-evaluation",
  "name": "Synthetic Data Evaluation",
  "description": "Synthetic data evaluation assesses whether synthetic datasets protect individual privacy while maintaining statistical utility and fidelity to real data. This technique evaluates three key dimensions: privacy (through disclosure risk metrics and re-identification attack success rates), utility (by comparing statistical properties and model performance), and fidelity (measuring distributional similarity to real data). It produces evaluation reports quantifying the privacy-utility-fidelity trade-offs.",
  "assurance_goals": [
    "Privacy",
    "Transparency",
    "Reliability"
  ],
  "tags": [
    "applicable-models/architecture/model-agnostic",
    "applicable-models/requirements/black-box",
    "assurance-goal-category/privacy",
    "assurance-goal-category/transparency",
    "assurance-goal-category/reliability",
    "data-requirements/training-data-required",
    "data-type/tabular",
    "data-type/any",
    "evidence-type/quantitative-metric",
    "evidence-type/documentation",
    "evidence-type/test-results",
    "expertise-needed/statistical-knowledge",
    "expertise-needed/domain-expertise",
    "expertise-needed/ml-engineering",
    "lifecycle-stage/data-collection",
    "lifecycle-stage/model-evaluation",
    "technique-type/analytical",
    "technique-type/testing"
  ],
  "example_use_cases": [
    {
      "description": "Validating synthetic patient data generated for medical research to ensure individual patients cannot be re-identified while maintaining statistical relationships needed for valid clinical studies.",
      "goal": "Privacy"
    },
    {
      "description": "Validating that machine learning models for predicting student outcomes trained on synthetic educational data maintain reliable performance comparable to models trained on real student records, while enabling researchers to share datasets without FERPA violations.",
      "goal": "Reliability"
    },
    {
      "description": "Ensuring fraud detection models trained on synthetic credit card transactions maintain reliable performance comparable to models trained on sensitive real transaction data.",
      "goal": "Reliability"
    }
  ],
  "limitations": [
    {
      "description": "Trade-off between privacy and utility means strong privacy guarantees often significantly degrade data quality and analytical value."
    },
    {
      "description": "Difficult to validate that synthetic data protects against all possible privacy attacks, especially sophisticated adversaries with auxiliary information."
    },
    {
      "description": "Utility metrics may not capture subtle distributional differences that matter for specific downstream tasks or edge case analyses."
    },
    {
      "description": "Synthetic data may introduce artificial patterns or miss rare but important real-world phenomena, limiting use for certain applications."
    },
    {
      "description": "Requires significant domain expertise to properly validate fidelity and utility for specific use cases, as generic statistical metrics may not capture domain-specific requirements or failure modes."
    },
    {
      "description": "Synthetic data may not preserve fairness properties or bias patterns from original data in predictable ways, requiring careful fairness testing when synthetic data is used to train decision-making models."
    }
  ],
  "resources": [
    {
      "title": "SCU-TrustworthyAI/SynEval",
      "url": "https://github.com/SCU-TrustworthyAI/SynEval",
      "source_type": "software_package"
    },
    {
      "title": "Evaluating synthetic data | Towards Data Science",
      "url": "https://towardsdatascience.com/evaluating-synthetic-data-c5833f6b2f15/",
      "source_type": "tutorial"
    },
    {
      "title": "Privacy Mechanisms and Evaluation Metrics for Synthetic Data Generation: A Systematic Review",
      "url": "https://www.semanticscholar.org/paper/e76d1dde9340ed1bfef28808297df51791ce4506",
      "source_type": "technical_paper",
      "authors": [
        "Pablo A. Osorio-Marulanda",
        "Gorka Epelde",
        "Mikel Hernandez",
        "Imanol Isasa",
        "Nicolas Moreno Reyes",
        "A. B. Iraola"
      ]
    },
    {
      "title": "Can We Trust Synthetic Data in Medicine? A Scoping Review of Privacy and Utility Metrics",
      "url": "https://www.semanticscholar.org/paper/5e1eb0df4db1316cff416aee9e7676517778a780",
      "source_type": "technical_paper",
      "authors": [
        "B. Kaabachi",
        "J. Despraz",
        "T. Meurers",
        "K. Otte",
        "M. Halilovic",
        "F. Prasser",
        "J. Raisaro"
      ]
    },
    {
      "title": "Welcome to TAPAS's documentation! â€” tapas 0.1 documentation",
      "url": "https://tapas-privacy.readthedocs.io/",
      "source_type": "documentation"
    }
  ],
  "related_techniques": [
    "membership-inference-attack-testing",
    "synthetic-data-generation",
    "differential-privacy",
    "machine-unlearning"
  ]
}