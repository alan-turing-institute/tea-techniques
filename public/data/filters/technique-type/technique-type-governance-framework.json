{
  "tag": {
    "name": "technique-type/governance-framework",
    "slug": "technique-type-governance-framework",
    "count": 1,
    "category": "technique-type"
  },
  "techniques": [
    {
      "slug": "model-development-audit-trails",
      "name": "Model Development Audit Trails",
      "description": "Model development audit trails create comprehensive, immutable records of all decisions, experiments, and changes throughout the ML lifecycle. This technique captures dataset versions, training configurations, hyperparameter searches, model architecture changes, evaluation results, and deployment decisions in tamper-evident logs. Audit trails enable reproducibility, accountability, and regulatory compliance by documenting who made what changes when and why, supporting post-hoc investigation of model failures or unexpected behaviours.",
      "assurance_goals": [
        "Transparency",
        "Reliability",
        "Safety"
      ],
      "tags": [
        "applicable-models/architecture/model-agnostic",
        "applicable-models/requirements/black-box",
        "assurance-goal-category/transparency",
        "assurance-goal-category/reliability",
        "assurance-goal-category/safety",
        "data-type/any",
        "lifecycle-stage/project-planning",
        "lifecycle-stage/data-collection",
        "lifecycle-stage/model-development",
        "lifecycle-stage/model-evaluation",
        "lifecycle-stage/deployment",
        "lifecycle-stage/post-deployment",
        "technique-type/procedural",
        "technique-type/governance-framework",
        "evidence-type/documentation",
        "expertise-needed/software-engineering",
        "expertise-needed/ml-engineering",
        "data-requirements/no-special-requirements"
      ],
      "example_use_cases": [
        {
          "description": "Maintaining detailed audit trails for medical AI development enabling investigators to trace how training data, model architecture, and evaluation decisions led to specific diagnostic behaviors during regulatory review.",
          "goal": "Transparency"
        },
        {
          "description": "Recording all model updates and performance changes over time to support root cause analysis when deployed systems exhibit unexpected behavior or reliability degradation.",
          "goal": "Reliability"
        },
        {
          "description": "Documenting safety-critical decisions like dataset filtering, bias testing, and red teaming results to demonstrate due diligence in preventing harmful deployments.",
          "goal": "Safety"
        },
        {
          "description": "Documenting credit scoring model development for regulatory compliance, maintaining detailed records of data sources, feature engineering decisions, fairness testing, and validation results to demonstrate adherence to fair lending requirements during audits.",
          "goal": "Transparency"
        },
        {
          "description": "Creating comprehensive audit trails for criminal justice risk assessment tools to enable external review of training data selection, bias mitigation techniques, and validation methodologies when legal challenges question algorithmic fairness.",
          "goal": "Fairness"
        },
        {
          "description": "Maintaining development logs for autonomous vehicle perception systems to support accident investigations, enabling forensic analysis of which model version was deployed, what training data informed its behavior, and what testing validated its safety.",
          "goal": "Safety"
        }
      ],
      "limitations": [
        {
          "description": "Comprehensive logging generates large volumes of data requiring significant storage infrastructure and data management."
        },
        {
          "description": "Audit trails may contain sensitive information about proprietary techniques, requiring careful access control and redaction procedures."
        },
        {
          "description": "Creating meaningful audit trails requires discipline and tooling integration that may slow development velocity."
        },
        {
          "description": "Retrospective analysis of audit trails can be time-consuming and requires expertise to extract actionable insights from complex logs."
        },
        {
          "description": "Implementing comprehensive audit trail systems requires integrating with diverse development tools (version control, experiment tracking, data pipelines), which can be complex and may require custom development for organisation-specific workflows."
        },
        {
          "description": "Storage costs can be substantial, with comprehensive model development projects generating terabytes of logs, experimental artifacts, and dataset versions requiring long-term retention for compliance purposes."
        }
      ],
      "resources": [
        {
          "title": "mlflow/mlflow",
          "url": "https://github.com/mlflow/mlflow",
          "source_type": "software_package"
        },
        {
          "title": "iterative/dvc",
          "url": "https://github.com/iterative/dvc",
          "source_type": "software_package"
        },
        {
          "title": "Advances in Data Lineage, Auditing, and Governance in Distributed Cloud Data Ecosystems",
          "url": "https://www.researchgate.net/publication/392917516_Advances_in_Data_Lineage_Auditing_and_Governance_in_Distributed_Cloud_Data_Ecosystems",
          "source_type": "technical_paper"
        },
        {
          "title": "Logging requirement for continuous auditing of responsible machine learning-based applications",
          "url": "https://link.springer.com/article/10.1007/s10664-025-10656-8",
          "source_type": "technical_paper"
        }
      ],
      "related_techniques": [
        "api-usage-pattern-monitoring",
        "out-of-domain-detection",
        "preferential-sampling",
        "relabelling"
      ]
    }
  ],
  "count": 1
}